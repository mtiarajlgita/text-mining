!pip install requests beautifulsoup4 nltk wordcloud matplotlib PySastrawi -q

import requests
from bs4 import BeautifulSoup
import re
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter
import nltk
from nltk.corpus import stopwords
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

# Download stopwords bahasa Indonesia
nltk.download('stopwords', quiet=True)

# URL artikel target
url = "https://ukmorbituinbkt.com/artikel/milad-ukm-orbit-ke-10-tahun-:-10-years-of-orbiting-making-a-breakthrough,-creating-change"

# Fungsi untuk mengambil teks dari website
def scrape_text_from_url(url):
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers, timeout=15)
    response.encoding = 'utf-8'
    soup = BeautifulSoup(response.content, 'html.parser')
    paragraphs = soup.find_all('p')
    return ' '.join([p.get_text(separator=' ', strip=True) for p in paragraphs])

# Fungsi untuk preprocessing teks
def preprocess_text(text, use_stemming=True):
    text = text.lower()                                  # Case folding
    text = re.sub(r'http\S+|www\S+|@\w+|#\w+|\S+@\S+', '', text)  # Hapus URL dan simbol
    text = re.sub(r'[^a-z\s]', ' ', text)                # Sisakan huruf dan spasi saja
    tokens = text.split()                                # Tokenizing

    stop_words = set(stopwords.words('indonesian'))
    additional_stops = {'url', 'http', 'https', 'com', 'org', 'www', 'nbsp',
                        'dengan', 'akan', 'yang', 'dan', 'di', 'ke', 'ini', 'itu',
                        'juga', 'adalah', 'oleh', 'pada', 'para', 'untuk'}
    stop_words.update(additional_stops)
    tokens = [w for w in tokens if w not in stop_words and len(w) > 2]  # Filtering

    if use_stemming:                                     # Stemming
        factory = StemmerFactory()
        stemmer = factory.create_stemmer()
        tokens = [stemmer.stem(w) for w in tokens]
    
    return ' '.join(tokens)

# Fungsi untuk menampilkan WordCloud
def generate_wordcloud(text, title="WordCloud"):
    wordcloud = WordCloud(
        width=1200,
        height=600,
        background_color='white',
        max_words=200,
        colormap='tab20b',
        random_state=42,
        collocations=False
    ).generate(text)
    
    plt.figure(figsize=(15, 8))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(title, fontsize=20, pad=20)
    plt.tight_layout()
    plt.show()
    wordcloud.to_file("wordcloud_result.png")            # Simpan hasil WordCloud

# Fungsi untuk menampilkan kata paling sering muncul
def show_top_words(text, n=10):
    words = text.split()
    counter = Counter(words)
    print(f"\nTop {n} kata yang paling sering muncul:")
    for word, freq in counter.most_common(n):
        print(f"{word}: {freq}")

# Jalankan proses scraping dan analisis
print("üîç Mengambil teks dari artikel...")
raw_text = scrape_text_from_url(url)
print("‚úÖ Jumlah karakter hasil scraping:", len(raw_text))

print("\n‚öô Melakukan preprocessing (case folding, tokenizing, filtering, stemming)...")
clean_text = preprocess_text(raw_text)
print("‚úÖ Jumlah kata setelah preprocessing:", len(clean_text.split()))

# Tampilkan hasil visualisasi dan analisis
generate_wordcloud(clean_text, title="WordCloud ‚Äì Milad UKM ORBIT ke-10")
show_top_words(clean_text, n=15)
